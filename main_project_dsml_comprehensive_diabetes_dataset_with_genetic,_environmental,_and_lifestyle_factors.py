# -*- coding: utf-8 -*-
"""Main_Project_DSML_Comprehensive Diabetes Dataset with Genetic, Environmental, and Lifestyle Factors.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1G_jjmFN5ur6ABKDNm6I8A5J6T5J658Eb

<font size="6" color="BLACK"><b><u>PROJECT TITLE</b></u></font>

<font size="6" color="magenta"><b>
<b><h1 align="center"> Comprehensive Diabetes Dataset with Genetic, Environmental, and Lifestyle Factors</h1>
<p align="center" Comprehensive Diabetes Dataset with Genetic, Environmental, and Lifestyle Factors</b></font>

<font size="6" color="black"><b><u>PROBLEM STATEMENT</b></u></font>

<p align="justify"><b>
<font size="4" color="darkred">Diabetes mellitus includes multiple subtypes, each with distinct causes and progression patterns. Understanding how genetic, environmental, and lifestyle factors interact is essential for personalized healthcare. This project analyzes a comprehensive dataset covering Steroid-Induced Diabetes, Neonatal Diabetes Mellitus (NDM), Prediabetes, Type 1 Diabetes, and Wolfram Syndrome to identify unique and shared risk factors. The challenge is to determine which factor combinations contribute to each subtype, enabling better diagnosis, targeted interventions, and effective disease management.

<font size="6" color="BLACK"><b><u>STAGE-1</b></u></font>
<font size="5" color="magenta"><b>

Dateset selection with Initial EDA</b></font>

<font size="6" color="BLACK"><b><u>DATASET</b></u></font>

<font size="6" color="BLACK"><b><u>Source</b></u></font>

<font size="5" color="red"><b>Kaggle (Contributor: Ankit Batra)
</font>

<font size="6" color="BLACK"><b><u>Timeline</b></u></font>

<font size="5" color="red"><b>Dataset released on 2024-09-01.
</font>

<font size="6" color="BLACK"><b><u>Location</b></u></font>

<font size="5" color="red"><b>Global dataset; not specific to any region
</font>

<font size="6" color="BLACK"><b><u>PROJECT OVERVIEW</b></u></font>

<font size="5" color="#FF00FF"><b><u>TITLE:</b></u></font>

<font size="5" color="BLue"><b>Comprehensive Diabetes Dataset with Genetic, Environmental, and Lifestyle Factors.</b></font>

<b>

- This project uses a comprehensive dataset encompassing multiple diabetes subtypes, including Steroid‑Induced Diabetes, Neonatal Diabetes Mellitus (NDM), Prediabetes, Type 1 Diabetes, and Wolfram Syndrome. The dataset includes medical, genetic, environmental, and lifestyle attributes to provide a holistic view of each patient’s profile. The aim is to help researchers and healthcare professionals understand how these factors interact and contribute to the development and progression of different diabetes subtypes, enabling insights for personalized treatment, risk assessment, and improved disease management.

<font size="5" color="#FF00FF"><b><u>GOALS</b></u></font>

<font size="5" color="black"><b><u>Risk Prediction:</b></u></font>
<b><p align="justify">
- Predict likelihood of developing specific diabetes subtypes using genetic, environmental, lifestyle, and medical data

<font size="5" color="black"><b><u>Feature Analysis & Interpretation:</b></u></font>
<b><p align="justify">
- Identify key factors and their interactions influencing each subtype.

<font size="5" color="black"><b><u>Subtype Classification:</b></u></font>
<b><p align="justify">
- Build a model to distinguish among the different diabetes types using available data (e.g. classify a new patient into Type 1 vs NDM vs Steroid‑Induced, etc.).

<font size="5" color="black"><b><u>Public Health Insights:</b></u></font>
<b>
- Inform preventive strategies to reduce risk, especially in genetically susceptible populations.

<font size="5" color="black"><b><u>Domain:</b></u></font>

<font size="5" color="#FF00FF"><b>Healthcare Analytics / Machine Learning for Disease Prediction</b></u></font>

<font size="5" color="black"><b><u>Objective:</b></u></font>
<b><p align="justify">

- Predictive Modeling: Develop a model to identify individuals at high risk of developing diabetes, supporting early intervention and personalized healthcare.

- Classification: Classify individuals as diabetic or non-diabetic based on genetic, environmental, and lifestyle factors.

<font size="5" color="black"><b><u>Type of problem:</b></u></font>

<font size="5" color="darkred"><b>
Classification (predict diabetes type / diabetes status)</b></u></font>

<font size="5" color="black"><b><u>Dataset Features description</b></u></font>


| Column Name                       | Data Type                      | Possible Values / Range                             | Description                                                      |
| --------------------------------- | ------------------------------ | --------------------------------------------------- | ---------------------------------------------------------------- |
| **Target**                        | Binary                         | `0`, `1`                                            | Whether the individual has diabetes (1) or not (0)               |
| **Genetic Markers**               | Categorical / Binary / Numeric | e.g. presence/absence or score values               | Indicators of genetic variants associated with diabetes risk     |
| **Autoantibodies**                | Categorical / Binary           | e.g. `Yes` / `No`                                   | Autoantibodies commonly associated with autoimmune diabetes      |
| **Family History**                | Binary / Categorical           | `Yes`, `No`                                         | Whether there is a family history of diabetes                    |
| **Environmental Factors**         | Categorical / Numeric          | e.g. exposure levels, quality indices               | Environmental influences (pollution, region, etc.)               |
| **Insulin Levels**                | Numeric                        | e.g. µU/mL                                          | Measured serum insulin level                                     |
| **Age**                           | Numeric                        | in years                                            | Age of individual                                                |
| **BMI**                           | Numeric                        | kg/m²                                               | Body Mass Index                                                  |
| **Physical Activity**             | Categorical / Ordinal          | e.g. `Low`, `Moderate`, `High`                      | Level of physical activity                                       |
| **Dietary Habits**                | Categorical / Ordinal          | e.g. `Poor`, `Average`, `Healthy`                   | Quality or pattern of diet                                       |
| **Blood Pressure**                | Numeric                        | mm Hg                                               | Systolic / Diastolic blood pressure                              |
| **Cholesterol Levels**            | Numeric                        | mg/dL or mmol/L                                     | Total / LDL / HDL cholesterol levels                             |
| **Waist Circumference**           | Numeric                        | cm                                                  | Waist measurement                                                |
| **Blood Glucose Levels**          | Numeric                        | mg/dL or mmol/L                                     | Fasting or random blood glucose                                  |
| **Ethnicity**                     | Categorical                    | e.g. `Asian`, `Caucasian`, etc.                     | Ethnic background of individual                                  |
| **Socioeconomic Factors**         | Categorical / Ordinal          | e.g. income brackets, education levels              | Socioeconomic status indicators                                  |
| **Smoking Status**                | Categorical                    | `Non‑smoker`, `Former`, `Current`                   | Smoking behavior                                                 |
| **Alcohol Consumption**           | Categorical                    | e.g. `None`, `Occasional`, `Frequent`               | Alcohol use frequency                                            |
| **Glucose Tolerance Test**        | Numeric / Categorical          | e.g. test value or pass/fail                        | Results from oral glucose tolerance test                         |
| **History of PCOS**               | Binary                         | `Yes`, `No`                                         | Whether the person has had Polycystic Ovary Syndrome             |
| **Previous Gestational Diabetes** | Binary                         | `Yes`, `No`                                         | History of gestational diabetes during pregnancy                 |
| **Pregnancy History**             | Numeric / Categorical          | number of pregnancies, or yes/no if pregnant before | Past pregnancy data                                              |
| **Weight Gain During Pregnancy**  | Numeric                        | kg or lbs                                           | Amount of weight gained during pregnancy                         |
| **Pancreatic Health**             | Categorical / Numeric          | e.g. test biomarkers or health status               | Health of pancreas (beta cell function, etc.)                    |
| **Pulmonary Function**            | Numeric / Categorical          | e.g. FEV1/FVC etc.                                  | Lung function measurement                                        |
| **Cystic Fibrosis Diagnosis**     | Binary                         | `Yes`, `No`                                         | Whether diagnosed with cystic fibrosis                           |
| **Steroid Use History**           | Binary / Categorical           | `None`, `Past`, `Current`                           | History of taking steroids (which can affect glucose metabolism) |
| **Genetic Testing**               | Categorical / Binary           | type of test, yes/no                                | Whether genetic testing was done, perhaps type of test           |
| **Neurological Assessments**      | Numeric / Categorical          | results, yes/no                                     | Assessment of nerve function if relevant                         |
| **Liver Function Tests**          | Numeric                        | e.g. levels of AST, ALT etc.                        | Indices of liver health                                          |
| **Digestive Enzyme Levels**       | Numeric                        | relevant enzyme values                              | Measures of digestive enzyme function                            |
| **Urine Test**                    | Categorical / Numeric          | e.g. presence of glucose, protein etc.              | Urine analysis results                                           |
| **Birth Weight**                  | Numeric                        | in kg or lbs                                        | Weight at birth                                                  |
| **Early Onset Symptoms**          | Categorical / Binary           | `Yes`, `No`, or symptom details                     | Symptoms that appeared early suggesting diabetes risk            |

<font size="5" color="black"><b><u>Dataset Github --> raw link</b></u></font>

<font size="5" color="#FF00FF"><b>
"https://raw.githubusercontent.com/Sripriya-DSML/Main_project-ML-Comprehensive-Diabetes-Dataset-with-Genetic-Environmental-and-Lifestyle-Factors/refs/heads/main/diabetes_dataset00.csv"

<font size="5" color="black"><b><u>INITIAL EDA</b></u></font>

<font size="5" color="blue"><b>Import all necessary modules and Loading the dataset from the github</b></font>

<font size="5" color="red"><b><u>Import Libraries</b></u></font>
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

"""<font size="5" color="green"><b><u>Load the Dataset</b></u></font>"""

url=("https://raw.githubusercontent.com/Sripriya-DSML/Main_project-ML-Comprehensive-Diabetes-Dataset-with-Genetic-Environmental-and-Lifestyle-Factors/refs/heads/main/diabetes_dataset00.csv")
df=pd.read_csv(url)

"""<font size="5" color="750075"><b><u>Shape of the Dataset</b></u></font>"""

print("Shape:", df.shape)

df.columns

"""<font size="5" color="blue"><b><u>To view first few rows</b></u></font>"""

# View first few rows
df.head()

"""<font size="5" color="FF0080"><b><u>To view column names and data types</b></u></font>"""

# Column names and data types
df.dtypes

"""<font size="5" color="00f0000000"><b><u>Basic information about data</b></u></font>"""

# basic information about data
df.info()

"""<font size="5" color="#FF00FF"><b><u>Summary statistics for numerical columns</b></u></font>"""

# Summary statistics for numerical columns
df.describe()

"""<font size="5" color="808000"><b><u>Check for Duplicates</b></u></font>"""

# Check for Duplicates
num_duplicates = df.duplicated().sum()
print("Number of duplicate rows:", num_duplicates)

# If you want to remove duplicates:
df_clean = df.drop_duplicates()

"""<font size="5" color="D100D1"><b><u>Check missing values</b></u></font>"""

# Check missing values
null_counts = df.isnull().sum()
print("Null values per column:\n",null_counts)

df['Target'].unique()

"""<font size="5" color="black"><b><u>Target feature</b></u></font>

<font size="5" color="black"><b><u>Target feature 1</b></u></font>
<b>
<font size="5" color="#FF00FF"><b><u>- Diabetes_Subtype</b></u></font>

<font size="5" color="black"><b><u>Target Classes / Values</b></u></font>

<font size="5" color="#FF00FF"><b><u>Class Value	Description</b></u></font>
    
  0: "Steroid-Induced Diabetes",

  1: "Neonatal Diabetes Mellitus (NDM)",

  2: "Prediabetic",
    
  3: "Type 1 Diabetes",
    
  4: "Wolfram Syndrome",

  5: "LADA",

  6: "Type 2 Diabetes",

  7: "Wolcott-Rallison Syndrome",

  8: "Secondary Diabetes",

  9: "Type 3c Diabetes (Pancreatogenic Diabetes)",

  10: "Gestational Diabetes",

  11: "Cystic Fibrosis‑Related Diabetes (CFRD)",

  12: "MODY"
  
<font size="5" color="800000"><b><u>Input feature</b></u></font>

<font size="5" color="#FF00FF"><b><u>feature1,feature 2....feature N All the other columns (except target)
</b></u></font>

1.Genetic Markers

2.Autoantibodies

3.Family History

4.Environmental Factors

5.Insulin Levels

6.Age

7.BMI (Body Mass Index)

8.Physical Activity

9.Dietary Habits

10.Blood Pressure

11.Cholesterol Levels

12.Waist Circumference

13.Blood Glucose Levels

14.Ethnicity

15.Socioeconomic Factors

16.Smoking Status

17.Alcohol Consumption

18.Glucose Tolerance Test

19.History of PCOS (Polycystic Ovary Syndrome)

20.Previous Gestational Diabetes

21.Pregnancy History

22.Weight Gain During Pregnancy

23.Pancreatic Health

24.Pulmonary Function

25.Cystic Fibrosis Diagnosis

26.Steroid Use History

27.Genetic Testing

28.Neurological Assessments

29.Liver Function Tests

30.Digestive Enzyme Levels

31.Urine Test

32.Birth Weight

33.Early Onset Symptoms

<font size="6" color="black"><b><u>Outcome:</b></u></font>

<font size="6" color="FF0080"><b><u>Diabetes Subtype Prediction Report</b></u></font>

<font size="6" color="800000"><b><u>Patient / Sample Input Features</b></u></font>
<b>
| Feature                      | Value     |
| ---------------------------- | --------- |
| Risk Score                   | 92.1      |
| Age                          | 45        |
| Blood Pressure               | 130       |
| Blood Glucose Levels         | 210       |
| Weight Gain During Pregnancy | 8.5       |
| Cholesterol Levels           | 220       |
| Waist Circumference          | 95        |
| Digestive Enzyme Levels      | 60        |
| Age Group                    | 3         |
| BMI                          | 29.3      |
| Pulmonary Function           | 88        |
| Insulin Levels               | 14.2      |
| Birth Weight                 | 3.5       |
| Neurological Assessments     | 75        |
| Pancreatic Health            | 65        |
| BMI Category                 | 2         |
| Genetic Marker 1             | 1         |
| Family History               | Yes       |
| Air Pollution Index          | 75        |
| Diet Score                   | 6         |
| Physical Activity            | Low       |
| Fasting Glucose              | 120 mg/dL |
| Insulin Level                | 10 µIU/mL |
| …                            | …         |

<b>

<font size="6" color="800000"><b><u>Sample Output</b></u></font>

<font size="5" color="black"><b><u>Predicted Diabetes Subtype Probabilities</b></u></font>
<b>

| Diabetes Subtype                 | Probability |
| -------------------------------- | ----------- |
| Prediabetes                      | 0.65        |
| Type 1 Diabetes                  | 0.15        |
| Steroid-Induced Diabetes         | 0.05        |
| Wolfram Syndrome                 | 0.02        |
| NDM (Neonatal Diabetes Mellitus) | 0.13        |

- Predicted Subtype: Prediabetes

<font size="5" color="darkgreen"><b><u>Top Contributing Features</b></u></font>
<b>

| Feature          | Contribution / Interpretation                            |
| ---------------- | -------------------------------------------------------- |
| Genetic Marker 1 | Presence increases genetic risk for Prediabetes.         |
| BMI              | Higher BMI is strongly associated with Prediabetes risk. |
| Diet Score       | Moderate diet score contributes to increased risk.       |


<font size="6" color="#FF00FF"><b><u>Interpretation:</b></u></font>
<p>

- Genetic Factors: Presence of Genetic_Marker_1 significantly increases Prediabetes risk.

- Lifestyle & Clinical Factors: High BMI and moderate diet score further elevate risk.

- Model Insight: Effectively captures complex interactions between genetic, clinical, and lifestyle variables, which may be missed by linear models.


<font size="6" color="darkred"><b><u>Sample Final Decision</b></u></font>

Chosen Model

- Reason for Selection: High accuracy, interpretability, and strong performance in multiclass diabetes subtype prediction.

- Final Prediction: Wolcott-Rallison Syndrome (55.95%)

- Although Prediabetes had the highest single-class probability (0.65), the final prediction incorporates overall model confidence, clinical relevance, and ensemble decision logic to ensure a data-driven and clinically meaningful outcome.

<font size="6" color="darkgreen"><b><u>Information about the dataset
</b></u></font>


<font size="5" color="black"><p><b>- Shape of the dataset:70000,34</b></font>

<font size="5" color="black"><p><b>- Number of columns:34</b></font>

<font size="5" color="black"><p><b>- Number of rows:70000</b></font>

<font size="5" color="black"><p><b>- Number of duplicate rows: 0</b></font>

<font size="5" color="black"><p><b>- Checking the nulls values:0</b></font>

<font size="6" color="black"><b><u>What are the algorithms you are going to use?
</b></u></font>

<font size="5" color="darkred"><b><u>For classification tasks like diabetes prediction,algorithm</b></u></font>
<p><b>
<font size="4" color="black"><b><u>Logistic Regression:</b></u></font>
 A fundamental algorithm for binary classification.

<font size="4" color="black"><b><u>Decision Tree Classifier:</b></u></font>
Decision Tree Classifier: Provides clear decision-making logic.

<font size="4" color="black"><b><u>Random Forest Classifier:</b></u></font>
Random Forest Classifier: An ensemble method that reduces overfitting.

<font size="4" color="black"><b><u>Gradient Boosting Machines (GBM):</b></u></font> Gradient Boosting Machines (GBM): Builds models sequentially to correct errors.
<font size="4" color="black"><b><u>Support Vector Machine (SVM):</b></u></font>
Effective in high-dimensional spaces.

<font size="4" color="black"><b><u>K-Nearest Neighbors:</b></u></font>K-Nearest Neighbors: (Classifies based on proximity to neighbors.KNN)

<font size="4" color="black"><b><u>Naive Bayes:</b></u></font> Assumes independence among features.

<font size="5" color="00cc00"><b><u>📈 Model Evaluation Metrics</b></u></font>

<font size="4" color="black"><b><u>Accuracy:</b></u></font>
Proportion of correct predictions.

<font size="4" color="black"><b><u>Precision:</b></u></font>Proportion of positive predictions that are actually correct.

<font size="4" color="black"><b><u>Recall (Sensitivity):</b></u></font>
Proportion of actual positives correctly identified.

<font size="4" color="black"><b><u>F1-Score:</b></u></font>Harmonic mean of precision and recall.

<font size="4" color="black"><b><u>Area Under ROC Curve (AUC-ROC):</b></u></font>Performance measurement for classification problems at various thresholds settings.

<font size="5" color="#FF00FF"><b><u>Perform Hyperparameter Tuning</b></u></font>
- Utilize techniques like Grid Search or Randomized Search to find the best hyperparameters:

<font size="4" color="black"><b><u>Grid Search:</b></u></font>
Exhaustively tests all combinations in the hyperparameter grid.

<font size="4" color="black"><b><u>Randomized Search:</b></u></font>
Samples a fixed number of hyperparameter combinations from the grid, offering a balance between exploration and computational efficiency.

<font size="5" color="black"><b>->This dataset going to use RandomizedSearchCV</b></font>

<font size="5" color="00f0000000"><b><u>Evaluate Model Performance</b></u></font>

- After tuning, assess the models performance using metrics like Accuracy, Precision, Recall, F1-Score, and AUC-ROC:

<font size="5" color="darkred"><b><u>“Final Sample Input & Output Prediction — Hyperparameter Tuning with RandomizedSearchCV and Combined Classifier Models”

<font size="6" color="BLACK"><b><u>STAGE-2</b></u></font>

<font size="6" color="00900"><b><u>EDA (Visualization) and Pre-processing</b></u></font>
"""

# Percentage missing
percent_missing = (null_counts / len(df)) * 100
print("Percent missing per column:\n", percent_missing)

"""<font size="6" color="FF0080"><b><u>Handling Missing Values & Handling Duplicates</b></u></font>

<font size="6" color="00900"><b><u>Interpretation:</b></u></font>

<font size="6" color="brown"><b><u>Data Integrity:</b></u></font>
<p><b>
All records are complete and unique, ensuring accurate analysis without the need for imputation or removal of duplicates.

<font size="6" color="brown"><b><u>Skewness:</b></u></font>
<p><b>Skewness refers to the asymmetry in the distribution of data around its mean. It indicates whether the data leans more towards the right (positive skew) or the left (negative skew).

<font size="6" color="00900"><b><u>Key Points</b></u></font>

<font size="4" color="00400"><b><u>Skewness Measures Asymmetry:</b></u></font>
<p> It quantifies the degree of distortion from a symmetrical bell curve or normal distribution.

<font size="4" color="brown"><b><u>Direction of Skewness:</b></u><font>
<p>Positive skew indicates a longer right tail, while negative skew indicates a longer left tail.

<font size="4" color="darkgreen"><b><u>Mean and Skewness:</b></u><font>
<p>The mean is typically greater than the median in a positively skewed distribution and less than the median in a negatively skewed distribution.

<font size="5" color="brown"><b><u>Skewness Values — What They Indicates</b></u><font>

<font size="4" color="00900"><b><u>Positive Skew (Right-Skewed):</b></u><font>

- Tail on the right side; mean > median.

- Skewness > 0 → right (positive) skew: tail extends to the right; many small values, a few large ones

<font size="4" color="00900"><b><u>Negative Skew (Left-Skewed):</b></u><font>
- Negative Skew (Left-Skewed): Tail on the left side; mean < median.

- Skewness < 0 → left (negative) skew: tail extends to the left; many larger values, a few small ones

<font size="4" color="00900"><b><u>Zero Skew:</b></u><font>

- Symmetrical distribution; mean ≈ median ≈ mode.

- Skewness ≈ 0 → approximately symmetric distribution

<font size="5" color="brown"><b><u>Handling Skewness with Transformations:</b></u><font>

<font size="5" color="brown"><b><u>Square Root:</b></u><font>
<b>
- Best for count data like the number of event occurrences or defects.when the data is moderately right-skewed.

<font size="5" color="brown"><b><u>Logarithmic:</b></u><font>
- Ideal for data with exponential growth patterns or wide-ranging values, such as income or population size.Data with a long right tail and values greater than zero; compresses large values effectively.

<font size="5" color="brown"><b><u>Cube Root:</b></u><font>
- Useful when data includes both positive and negative values, like temperature changes or financial gains/losses and square root transformation isn't sufficient.

<font size="5" color="darkvoilet"><b><u>Outliers</b></u><font>

<font size="5" color="green"><b><u>What Are Outliers in ML?</b></u><font>
<p><b>
- Outliers are data points that significantly differ from the majority of the data. They can arise due to:

<font size="5" color="darkvoilet"><b><u>Measurement errors:</b></u><font>

- Mistakes during data collection.

<font size="5" color="darkbrown"><b><u>Data entry errors:</b></u><font>

Data entry errors: Incorrect data input.

<font size="5" color="brown"><b><u>Natural variation: </b></u><font>

- Genuine but rare occurrences.

<font size="5" color="yellowdark"><b><u>Novel data:</b></u><font>
- New patterns or behaviors not previously observed.</b></u><font>

<font size="5" color="008000"><b><u>Common Methods to Detect Outliers (IQR, Z-Score)</b></u><font>


<font size="5" color="brown"><b><u>1. Boxplot (Tukey’s Method)</b></u><font>
<b>

How it works:

<font size="5" color="darkviolet"><b><u>Calculate the Interquartile Range (IQR):</b></u><font>


IQR=Q3−Q1

where:

Q1 = 1st quartile (25th percentile)
Q3 = 3rd quartile (75th percentile)

Define outlier thresholds:

Lower bound:
𝑄
1
−
1.5
×
IQR
Q1−1.5×IQR

Upper bound:
𝑄
3
+
1.5
×
IQR
Q3+1.5×IQR

<u>Outliers:</u> Data points outside these bounds.

<u>Use case:</u> Effective for univariate data with skewed distributions.

<font size="5" color="brown"><b><u>2. Z-Score</b></u><font>
<b>

How it works:

<font size="5" color="darkviolet"><b><u>Calculate the Z-score for each data point:</b></u><font>
<b>

𝑍=(𝑋−𝜇)/𝜎

where:

X = data point

μ = mean of the data

σ = standard deviation

<u>Define outlier threshold:</u> Typically, a Z-score beyond ±3 indicates an outlier.

<u>Use case:</u> Suitable for normally distributed data.

<font size="5" color="darkviolet"><b><u>Outliers and Skewness</b></u><font>
<b>

# **Steps:**
<font size="5" color="brown"><b><u></b></u><font>
<b>
1. Identify numeric columns
2. Shape Before Removing Outliers
3. Skewness Before Outlier Removal
4. Boxplots Before Removing Outliers
5. Removing Outliers Using IQR Method
6. Shape After Removing Outliers
7. Skewness After Outlier Removal
8. Boxplots After Removing Outliers
9. Compare histograms / KDE before vs after display
10. Applying Transformations (Log/Square Root)
11. Skewness After Transformation
11. Boxplots After Transformation

<font size="5" color="008000"><b>1.<u>Identify numeric columns</b></u></font>

<font size="5" color="black"><b><u>Purpose:</b></u></font>

<font size="4" color="darkviolet"><b>Identifies columns with numerical data types for subsequent analysis.</b></font>


<font size="5" color="brown"><b><u>Interpretation:</b></u></font>
<b>
- Ensures that only relevant columns are considered, excluding categorical or non-numeric data that might skew results.
"""

# 1. Identify numeric columns
num_cols = df.select_dtypes(include=[np.number]).columns.tolist()
print("Numeric columns:", num_cols)

"""<font size="5" color="008000"><b>2.<u>Shape Before Removing Outliers</b></u></font>

<font size="5" color="black"><b><u>Purpose:</b></u></font>

<font size="4" color="darkviolet"><b>Displays the number of rows and columns before any data cleaning.</b></font>


<font size="5" color="brown"><b><u>Interpretation:</b></u></font>
<b>
- Provides a baseline to assess how much data is retained after outlier removal.

"""

# 2. Shape Before Removing Outliers
print("Shape before removing outliers:", df.shape)

"""<font size="5" color="008000"><b>3.<u>Skewness Before Outlier Removal</b></u></font>

<font size="5" color="black"><b><u>Purpose:</b></u></font>

<font size="4" color="darkviolet"><b>Calculates the skewness of each numeric column.</b></font>


<font size="5" color="brown"><b><u>Interpretation:</b></u></font>
<b>
- Positive skew indicates a right-skewed distribution (long tail on the right).

- Negative skew indicates a left-skewed distribution (long tail on the left).

- Skewness values close to 0 suggest a symmetric distribution.


<font size="5" color="darkviolet"><b><u>Reference:</b></u></font>
<b>
- Skewness measures the asymmetry of the data distribution.
"""

# 3. Skewness before
skew_before = df[num_cols].skew()
print("Skewness before outlier removal:\n", skew_before)

"""<font size="5" color="008000"><b>4.<u>Boxplots Before Removing Outliers</b></u></font>

<font size="5" color="black"><b><u>Purpose:</b></u></font>
<b>

<font size="5" color="darkviolet"><b>Visualizes the distribution of each numeric column.</b></font>



<font size="5" color="brown"><b><u>Interpretation:</b></u></font>
<font color="brown"><b>

1.The box represents the interquartile range (IQR), with the line inside the box indicating the median.

2.Whiskers extend to 1.5 times the IQR; points outside this range are considered potential outliers.

3.A skewed distribution will show an asymmetric box and whiskers.



"""

# 4. Boxplots before removing outliers
for col in num_cols:
    plt.figure(figsize=(5,3))
    sns.boxplot(x=df[col].dropna())
    plt.title(f"Before — {col}")
    plt.tight_layout()
    plt.show()

"""<font size="5" color="green"><b>5.<u>Removing Outliers Using IQR Method</b></u></font>

<font size="5" color="black"><b><u>Purpose:</b></u></font>

<font size="4" color="darkviolet"><b>Removes data points that are outside 1.5 times the IQR from the first and third quartiles.</b></font>


<font size="5" color="brown"><b><u>Interpretation:</b></u></font>
<font color="brown"><b>

- This method helps in eliminating extreme values that could distort statistical analyses.

- However, it may also remove valid data points, so it's essential to consider the context.
"""

# 5. Define function to remove outliers (IQR method)
def remove_outliers_iqr(data, col):
    Q1 = data[col].quantile(0.25)
    Q3 = data[col].quantile(0.75)
    IQR = Q3 - Q1
    lower = Q1 - 1.5 * IQR
    upper = Q3 + 1.5 * IQR
    return data[(data[col] >= lower) & (data[col] <= upper)]
# Remove outliers for all numeric columns
df_clean = df.copy()
for col in num_cols:
    if df_clean[col].dropna().nunique() > 1:
        df_clean = remove_outliers_iqr(df_clean, col)

"""<font size="5" color="green"><b>6.<u>Shape After Removing Outliers</b></u></font>

<font size="5" color="black"><b><u>Purpose:</b></u></font>

<font size="4" color="darkviolet"><b>Shows the number of rows and columns after outlier removal.</b></font>


<font size="5" color="brown"><b><u>Interpretation:</b></u></font>
<font color="brown"><b>

- A reduction in rows indicates how many data points were considered outliers and removed.
"""

# 6. Shape after removing outliers
print("Shape after removing outliers:", df_clean.shape)

"""<font size="5" color="green"><b>7.<u>Skewness After Outlier Removal</b></u></font>

<font size="5" color="black"><b><u>Purpose:</b></u></font>

<font size="4" color="darkviolet"><b>Recalculates skewness after outlier removal.</b></font>

<font size="5" color="brown"><b><u>Interpretation:</b></u></font>
<font color="brown"><b>

- Outlier removal can reduce skewness, leading to a more symmetric distribution.

- therefore if skewness remains high, further transformations might be necessary.
"""

# 7. Skewness after outlier removal
skew_after = df_clean[num_cols].skew()
print("Skewness after outlier removal:\n", skew_after)

"""<font size="5" color="green"><b>8.<u>Boxplots After Removing Outliers</b></u></font>

<font size="5" color="black"><b><u>Purpose:</b></u></font>

<font size="4" color="darkviolet"><b>Visualizes the distribution of each numeric column after outlier removal.</b></font>

<font size="5" color="brown"><b><u>Interpretation:</b></u></font>
<font color="brown"><b>

- The boxplots should show reduced whisker lengths and fewer outliers.

- A more symmetric box indicates a more normal distribution.
"""

# 8. Boxplots after removing outliers
for col in num_cols:
    plt.figure(figsize=(5,3))
    sns.boxplot(x=df_clean[col].dropna())
    plt.title(f"After — {col}")
    plt.tight_layout()
    plt.show()

"""<font size="5" color="green"><b>9.<u>Compare histograms / KDE before vs after display</b></u></font>

<font size="5" color="black"><b><u>Purpose:</b></u></font>

<font size="4" color="darkviolet"><b>Compares the distribution of each numeric column before and after outlier removal.</b></font>

<font size="5" color="brown"><b><u>Interpretation:</b></u></font>
<font color="brown"><b>

- A more bell-shaped histogram after cleaning suggests a move towards normality.

- KDE (Kernel Density Estimate) plots provide a smoothed view of the distribution.
"""

# 9. Compare histograms / KDE before vs after display
for col in num_cols:
    fig, axes = plt.subplots(1,2, figsize=(10,4))
    sns.histplot(df[col].dropna(), kde=True, ax=axes[0])
    axes[0].set_title(f"Before — {col}")
    sns.histplot(df_clean[col].dropna(), kde=True, ax=axes[1])
    axes[1].set_title(f"After — {col}")
    plt.tight_layout()
    plt.show()

"""<font size="5" color="green"><b>10.<u>Applying Transformations (Log/Square Root)</b></u></font>

<font size="5" color="black"><b><u>Purpose:</b></u></font>

<font size="4" color="darkviolet"><b>Applies transformations to reduce skewness.</b></font>

<font size="5" color="brown"><b><u>Interpretation:</b></u></font>
<font color="brown"><b>

Skewness Reduction Strategy

- High Positive Skew (skew > 1): Apply log1p to compress large values and reduce right-tail skew.

- Moderate Skew (0.5 < skew ≤ 1): Apply square root transform for gentler reduction of extreme values.

- Low Skew (≤ 0.5): Leave unchanged to avoid unnecessary distortion.
"""

# 10. Apply transformations (sqrt or log) to reduce skewness
df_trans = df_clean.copy()
for col in num_cols:
    # Only transform non‑negative columns (for sqrt / log)
    if (df_clean[col] >= 0).all():
        # Choose transform based on skewness magnitude
        if skew_after[col] > 1:
            # high right skew — use log
            df_trans[col] = np.log1p(df_clean[col])
        elif skew_after[col] > 0.5:
            # moderate skew — sqrt
            df_trans[col] = np.sqrt(df_clean[col])
        else:
            # less skew — keep as is (or minor transform)
            df_trans[col] = df_clean[col]

"""<font size="5" color="green"><b>11.<u>Skewness After Transformation</b></u></font>

<font size="5" color="black"><b><u>Purpose:</b></u></font>

<font size="4" color="darkviolet"><b>Calculates the skewness of each numeric column after applying transformations</b></font>

<font size="5" color="brown"><b><u>Interpretation:</b></u></font>
<font color="brown"><b>

Expected Outcome:

- A reduction in skewness values indicates that the transformations have made the distributions more symmetric.

- While transformations can reduce skewness, achieving a perfectly normal distribution is not always possible
"""

# 11. Skewness after transformation
skew_trans = df_trans[num_cols].skew()
print("Skewness after transformation:\n", skew_trans)

"""<font size="5" color="green"><b>12.<u>Boxplots After Transformation</b></u></font>

<font size="5" color="black"><b><u>Purpose:</b></u></font>

<font size="4" color="darkviolet"><b>Visualize numeric column distributions after applying transformations.</b></font>

<font size="5" color="brown"><b><u>Interpretation:</b></u></font>
<font color="brown"><b>

Expected Outcome:
- More symmetric distributions with reduced skewness.

Insights:

- Right-skewed data: Log or square root transformations reduce skewness.

- Left-skewed data: May require reflection or alternative transformations to correct skew.
"""

# 12. Boxplots after transformation
for col in num_cols:
    plt.figure(figsize=(5, 3))
    sns.boxplot(x=df_trans[col].dropna(), color='skyblue')
    plt.title(f"Boxplot of Transformed '{col}'")
    plt.tight_layout()
    plt.show()

"""<font size="6" color="FF0080"><b><u>Visualization</b></u></font>

<font size="5" color="blue"><b><u>Univariate Visualizations</b></u></font>
<b>
- These visualize the distribution of a single variable at a time.
- These will help you see skew, tails, outliers, modality, etc.

<font size="5" color="brown"><b>1.<u>Plotting the Histogram Visualizations</b></u></font>
"""

# 1.Plotting the Histogram
sns.histplot(df["Insulin Levels"], kde=True)
plt.title("Distribution of Insulin Levels")
plt.show()

"""<font size="5" color="FF0080"><b><u>Insulin Levels Histogram & KDE Interpretation</b></u></font>
<b>

- Shape: Histogram shows frequency; KDE provides a smoothed probability density curve.

- Skewness: Right-skewed suggests fewer but extreme high insulin values; left-skewed indicates the opposite.

- Central Tendency: KDE peak indicates the most common insulin level.

- Spread: Wider histogram/KDE reflects greater variability.

- Outliers: Values far from the peak indicate rare or extreme insulin levels.

<font size="5" color="brown"><b>2.<u>Plotting the Boxplot Visualizations</b></u></font>
"""

# 2. plotting Boxplot
sns.boxplot(y=df["BMI"])
plt.title("Boxplot of BMI")
plt.show()

"""<font size="5" color="FF0080"><b><u>BMI Boxplot Interpretation</b></u></font>

 <b>

- Median: Bold line inside the box indicates central tendency.

- Interquartile Range (IQR): Box spans Q1–Q3, showing middle 50% of data; wider box = more variability.

- Whiskers: Extend 1.5× IQR, showing data spread.

- Outliers: Points outside whiskers represent extreme values.

- Skewness: Median position relative to Q1/Q3 indicates negative or positive skew.

<font size="5" color="brown"><b>3.<u>Plotting the violin Visualizations</b></u></font>
"""

# 3. Violin plot
sns.violinplot(x=df["Blood Glucose Levels"])
plt.title("Violin plot of Blood Glucose Levels")
plt.show()

"""<font size="5" color="FF0080"><b><u>Blood Glucose Levels Violin Plot Interpretation</b></u></font>
 <b>

- Distribution: Bimodal, with two peaks indicating two main groups of individuals. Wider sections show higher data concentration.

- Median & IQR: Median ~150; the box inside the violin shows the interquartile range (middle 50% of data).

- Range: Whiskers show min–max within the box range; full violin spans 80–300 blood glucose levels.

<font size="5" color="brown"><b>4.<u>Plotting the KDEDensity plot/kde Visualizations</b></u></font>:
"""

# 4. Plotting the KDEDensity plot/kde
sns.kdeplot(df["Age"], shade=True)
plt.title("Kernel Density of Age")
plt.show()

"""<font size="5" color="FF0080"><b><u>Age Variable Kernel Density Plot Interpretation</b></u></font>
 <b>

- Peaks (Modes): Prominent around ages 5, 15, and a broader peak between 30–60, indicating common age groups.

- Density: Higher values show ages that occur more frequently.

- Overall Shape: Multimodal distribution suggests multiple distinct age groups within the dataset, spanning 0–80 years, with concentrations in teens and middle age.

<font size="5" color="brown"><b>5.<u>Plotting the histogram with KDE Visualizations</b></u></font>:
"""

# Plotting the histogram with KDE
sns.histplot(df["Cholesterol Levels"], kde=True)
plt.title("Histogram with KDE of Cholesterol Levels")
plt.show()

"""<font size="5" color="FF0080"><b><u>Cholesterol Levels Histogram & KDE Interpretation</b></u></font>
 <b>

- X-axis: Cholesterol levels (100–300)

- Y-axis: Frequency of individuals

- Histogram: Highest frequency around 150–200.

- KDE Plot: Smooth curve shows a bimodal distribution with peaks near 175 and 225, indicating two common cholesterol ranges in the population.

<font size="5" color="blue"><b><u>Bivariate Visualizations</b></u></font>
<b>
- Bivariate analysis is simply studying how two variables relate to each other.

<font size="5" color="green"><b>1.<u>Numeric vs Numeric — BMI vs Blood Glucose Levels</b></u></font>
"""

# 1.Numeric vs Numeric — BMI vs Blood Glucose Levels
sns.scatterplot(data=df, x="BMI", y="Blood Glucose Levels")
plt.title("BMI vs Blood Glucose Levels")
plt.show()

"""<font size="5" color="FF0080"><b><u>BMI vs Blood Glucose Levels Interpretation</b></u></font>
 <b>

- Trend: Positive correlation—higher BMI generally corresponds to higher blood glucose levels.

- Data Pattern: Points clustered by BMI values, showing a range of glucose levels per BMI.

Observations:

- Highest glucose levels (up to 300) occur in BMI 16–24.

- BMI >25 shows glucose levels concentrated between ~125–250.

<font size="5" color="green"><b>2.<u>Numeric vs Categorical — Blood Pressure by Target (diabetes vs not)</b></u></font>
"""

# 2.Numeric vs Categorical — Blood Pressure by Target (diabetes vs not)
plt.figure(figsize=(25, 10))
sns.boxplot(data=df, x="Target", y="Blood Pressure",palette="dark")
plt.title("Blood Pressure by Diabetes Status")
plt.show()

"""<font size="5" color="FF0080"><b><u>Blood Pressure by Diabetes Status (Box Plot Interpretation)</b></u></font>
<b>
- Axes: X = Diabetes-related conditions (Target), Y = Blood Pressure (60–150).

- Box Plots: Show median, quartiles, and range for each diabetes status.

- Insight: Compares blood pressure distributions across different diabetes conditions, highlighting variations and trends among groups.

<font size="5" color="green"><b>3.<u>Categorical vs Numeric — Physical Activity groups vs Insulin Levels</b></u></font>
"""

# 3.Categorical vs Numeric — Physical Activity groups vs Insulin Levels
sns.boxplot(data=df, x="Physical Activity", y="Insulin Levels",palette="dark")
plt.title("Insulin Levels by Physical Activity")
plt.show()

"""<font size="5" color="FF0080"><b><u>Insulin Levels by Physical Activity (Box Plot Summary)</b></u></font>
<b>

- Median: ~19 for all activity groups.

- IQR: Similar across groups, ~13–28.

- Range (Whiskers): ~5–49, excluding outliers.

- Insight: Insulin level distributions are similar across High, Moderate, and Low activity, showing no significant differences.

<font size="5" color="green"><b>4.<u>Numeric vs Numeric — Age vs Cholesterol Levels</b></u></font>
"""

# 4.Numeric vs Numeric — Age vs Cholesterol Levels
sns.scatterplot(data=df, x="Age", y="Cholesterol Levels", hue="Age", palette="viridis")
plt.title("Age vs Cholesterol Levels (colored by Age)")
plt.show()

"""<font size="5" color="FF0080"><b><u>Age vs Cholesterol Levels Scatter Plot Interpretation</b></u></font>
<b>

- Trend: Cholesterol levels generally increase with age.

- Axes: Age (0–80), Cholesterol (100–300).

- Color coding: Purple = younger, Yellow = older, showing age-based gradient.

<font size="5" color="green"><b>5.<u>Age (numeric) vs Blood Pressure (numeric)</b></u></font>
"""

# 5.Age (numeric) vs Blood Pressure (numeric)
sns.scatterplot(data=df, x="Age", y="Blood Pressure", hue="Age")
plt.title("Age vs Blood Pressure")
plt.show()

"""<font size="5" color="FF0080"><b><u>Age vs Blood Pressure Scatter Plot Interpretation</b></u></font>
<b>

- Shows a positive correlation: blood pressure increases with age.

- Axes: Age (0–80), Blood Pressure (60–150).

- Color coding: Lighter points = younger, darker points = older.

- Clusters: Distinct groups suggest age ranges with corresponding blood pressure patterns.

<font size="5" color="ff0080"><b><u>Multivariate Visualizations</b></u></font>
<b>
- Graphical representation of three or more variables to reveal complex relationships and patterns, unlike univariate or bivariate plots.

<font size="5" color="blue"><b>1.<u>Pairplot Multiple numeric features by target</b></u></font>
<b>
"""

# Multiple numeric features pairplot by target
numeric_cols = ["BMI", "Age", "Blood Pressure", "Cholesterol Levels", "Insulin Levels", "Waist Circumference", "Blood Glucose Levels"]
sns.pairplot(df, vars=numeric_cols, hue="Target", palette="coolwarm", plot_kws={"alpha":0.5})
plt.suptitle("Pairplot of numeric features by Target", y=1.02)
plt.show()

"""<font size="5" color="FF0080"><b><u>Pairplot Interpretation</b></u></font>
<b>

- Class Separation: Distinct clusters of classes in scatter plots indicate strong predictive features (e.g., BMI vs Blood Glucose).

- Correlation Patterns: Narrow scatter indicates high correlation (e.g., Blood Glucose vs Insulin, Waist Circumference vs BMI).

- Distribution Differences: Diagonal histograms show class-specific distributions; separate peaks suggest useful features.

- Overlapping vs Separation: Features with overlapping class points are less informative; clear separation enhances classification.

<font size="5" color="blue"><b>2.<u>Heatmap of Correlation Matrix</b></u></font>
"""

# 2.Heatmap of Correlation Matrix
numeric_df = df.select_dtypes(include=['number'])
plt.figure(figsize=(10,8))
sns.heatmap(numeric_df.corr(), annot=True, fmt=".2f", cmap="coolwarm")
plt.title("Correlation Heatmap (Numeric Features Only)")
plt.show()

"""<font size="5" color="FF0080"><b><u>Correlation Heatmap Summary</b></u></font>
<b>

- Visualizes correlations between numeric health features.

- Red: Positive correlation, Blue: Negative correlation, White: Little/no correlation.

Examples:

1.Blood Pressure & Age: 0.76 (strong positive)

2.Blood Glucose & Pulmonary Function: -0.60 (strong negative)

<font size="5" color="blue"><b>3.<u>Histograms for Four Variables</b></u></font>
"""

# Histograms for Four Variables
variables = ['Age', 'BMI', 'Blood Pressure', 'Cholesterol Levels']
# Create the plot
plt.figure(figsize=(10, 6))
for var in variables:
    sns.histplot(df[var], label=var, kde=True, alpha=0.5)
plt.title('Distributions of Multiple Variables')
plt.xlabel('Values')
plt.ylabel('Frequency')
plt.legend(title='Variables')
plt.grid(True)
plt.show()

"""<font size="5" color="FF0080"><b><u>Histogram Summary</b></u></font>
<b>

- Age: Left-skewed, highest frequency at younger ages.

- BMI: Left-skewed, peaks in lower range.

- Blood Pressure: Bimodal, two distinct peaks.

- Cholesterol: Right-skewed, long tail toward higher values.

<font size="6" color="BLACK"><b><u>STAGE-3</b></u></font>

<font size="6" color="darkred"><b><u>Feature Selection and Model Building (using multiple models)</b></u></font>

<font size="6" color="BLACK"><b><u>Feature Engineering</b></u></font>
"""

# Make a working copy
df_copy = df.copy()
print("Copied dataframe shape:", df_copy.shape)

# To find target unique names
unique_names = df_copy['Target'].unique().tolist()
print("Unique target names:", unique_names)
df_copy_unique = pd.DataFrame({"Unique_Target": unique_names})
print(df_copy_unique)

# Inspect unique values for columns you plan to ordinal‑encode
for col in ['Physical Activity', 'Dietary Habits', 'Socioeconomic Factors']:
    print(col, "→ unique values:", df_copy[col].unique())
    print(col, "value counts:\n", df_copy[col].value_counts(), "\n")

# label encode
from sklearn.preprocessing import LabelEncoder, OrdinalEncoder
label_cols = ['Target',
    'Smoking Status', 'Alcohol Consumption',
    'Glucose Tolerance Test', 'History of PCOS',
    'Previous Gestational Diabetes', 'Pregnancy History',
    'Liver Function Tests', 'Early Onset Symptoms'
]
le = LabelEncoder()
for col in label_cols:
    if col in df_copy.columns:
        df_copy[col] = le.fit_transform(df_copy[col].astype(str))

# Ordinal encode ordered categorical features
ordinal_features = ['Physical Activity', 'Dietary Habits', 'Socioeconomic Factors']
# Define the order lists (adjust based on your domain / unique values)
ordinal_order = [
    ['Low', 'Moderate', 'High'],             # Physical Activity
    ['Healthy', 'Unhealthy'],                # Dietary Habits
    ['Low', 'Middle', 'High']                # Socioeconomic Factors
]
oe = OrdinalEncoder(categories=ordinal_order, handle_unknown='use_encoded_value', unknown_value=-1)
# Only encode if columns exist
cols_present = [c for c in ordinal_features if c in df_copy.columns]
if cols_present:
    df_copy[cols_present] = oe.fit_transform(df_copy[cols_present].astype(str))

# One‑hot encode nominal (non-ordered) categorical features
from sklearn.preprocessing import OneHotEncoder
one_hot_cols = [
    'Genetic Markers', 'Autoantibodies', 'Family History', 'Environmental Factors',
    'Ethnicity', 'Cystic Fibrosis Diagnosis', 'Steroid Use History',
    'Genetic Testing', 'Urine Test'
]
cols_to_dummy = [c for c in one_hot_cols if c in df_copy.columns]
if cols_to_dummy:
    df_copy = pd.get_dummies(df_copy, columns=cols_to_dummy, drop_first=True)
df_copy

# print Feaure Engineering
print("✅ Feature engineering complete.")
print("After feature engineering shape:", df_copy.shape)
print(df_copy.head())

"""<font size="6" color="darkgreen"><b><u>Feature Creation</b></u></font>"""

from sklearn.preprocessing import LabelEncoder, StandardScaler

#  1. Age Group
df_copy['Age_Group'] = pd.cut(
    df_copy['Age'],
    bins=[0, 30, 45, 60, 100],
    labels=['Young', 'Adult', 'Middle', 'Senior']
)
# 2.BMI Category
df_copy['BMI_Category'] = pd.cut(
    df_copy['BMI'],
    bins=[0, 18.5, 25, 30, 100],
    labels=['Underweight', 'Normal', 'Overweight', 'Obese']
)

# 3. High-Risk Pregnancy
df_copy['High_Risk_Pregnancy'] = (
    (df_copy.get('Previous Gestational Diabetes', 0) == 1)
    | (df_copy.get('Weight Gain During Pregnancy', 0) > df_copy.get('Weight Gain During Pregnancy', 0).median())
    | (df_copy.get('History of PCOS', 0) == 1)
).astype(int)

# 4. Risk score
df_copy['Risk_Score'] = (
    df_copy['Age'] * 0.3
    + df_copy['BMI'] * 0.2
    + df_copy.get('blood_glucose_levels', 0) * 0.4
    + df_copy.get('blood_pressure', 0) * 0.1
)

# Encoding categorical features
label_encoder = LabelEncoder()

# Encode 'Age_Group' and 'BMI_Category'
df_copy['Age_Group'] = label_encoder.fit_transform(df_copy['Age_Group'])
df_copy['BMI_Category'] = label_encoder.fit_transform(df_copy['BMI_Category'])
# print
print("Features created and encoded Shape:", df_copy.shape)
df_copy.head().round(2)

# before columns types
df_copy.dtypes

# length of the target
len(df_copy['Target'].unique())

# convert bool to int
bool_cols = df_copy.select_dtypes(include=['bool']).columns
df_copy[bool_cols] = df_copy[bool_cols].astype(int)

# convert float to int
float64=df_copy.select_dtypes(include=['float64']).columns
df_copy[float64] = df_copy[float64].astype(int)

# This will display the number of rows and columns in df_copy after scaling.
print("Number of rows:", df_copy.shape[0])
print("Number of columns:", df_copy.shape[1])

# after convert columns types
df_copy.dtypes

df_copy.head()

"""<font size="6" color="darkgreen"><b><u>Separate features and target</b></u></font>"""

# Separate features and target

X = df_copy.drop(columns=['Target'])
y = df_copy['Target']
# Purpose: This step divides the dataset into two parts: X contains all the features (independent variables), and y contains the target variable (dependent variable).

# Split the data into training and testing sets
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

# Print shapes
# Print the sizes / shapes
print("Full dataset shape:", df_copy.shape)
print("X_train shape:", X_train.shape)
print("y_train shape:", y_train.shape)
print("X_test shape:", X_test.shape)
print("y_test shape:", y_test.shape)

# This indicates that X has 70000 samples, each with 39 features, and y has 70000 corresponding target labels.

"""<font size="6" color="darkgreen"><b><u>Feature Scaling</b></u></font>"""

from sklearn.preprocessing import StandardScaler

# Initialize the scaler
scaler = StandardScaler()

# Fit on training data and transform
X_train_scaled = scaler.fit_transform(X_train)

# Transform the test data using the same scaler
X_test_scaled = scaler.transform(X_test)

"""<font size="6" color="darkgreen"><b><u>Feature Selection</b></u></font>"""

from sklearn.feature_selection import SelectKBest, f_classif
# Feature Selection with SelectKBest
k = 30  # Number of top features to select
selector = SelectKBest(score_func=f_classif, k=k)
selector.fit(X_train_scaled, y_train)
# Purpose: SelectKBest is used to select the top k features based on their individual performance in predicting the target variable.
# The f_classif function computes the ANOVA F-value between each feature and the target, which is a measure of the feature's relevance.

# Get Retrieving Selected Features names
selected_features = X.columns[selector.get_support()]
print("Selected Features:", selected_features)
# Purpose: This retrieves the names of the features that were selected by SelectKBest and prints them out.

# Create a DataFrame of feature scores
X_selected=X[selected_features]
scores = selector.scores_
feature_scores = pd.DataFrame({
    'Feature': X.columns,
    'Score': scores
}).sort_values(by='Score', ascending=False)
# Purpose: This creates a DataFrame that pairs each feature with its corresponding score and sorts them in descending order. This allows for easy inspection of which features have the highest scores.

# Display top 30 features by score
print("Top 30 Features by Score:")
print(feature_scores.head(30))
# Purpose: This prints out the top 30 features based on their scores, providing insight into which features are most influential in predicting the target variable.

# correlation matrix
numeric_cols = X.select_dtypes(include=np.number).columns.tolist()
corr_matrix = df_copy[numeric_cols].corr()
plt.figure(figsize=(30, 8))
sns.heatmap(corr_matrix, annot=True, fmt=".2f", cmap="coolwarm")
plt.title("Correlation Matrix")
plt.show()

"""<font size="6" color="voilet"><b><u>Feature Selection Summary</b></u></font>
<b>

- Top 30 features selected using SelectKBest (f_classif) for strong individual predictive power.

- Limitation: Ignores feature interactions and redundancy.

<font size="6" color="darkred"><b><u>Shape of the dataframe before building</b></u></font>
"""

# print the shape of the dataframe before building
print("DataFrame shape:", df_copy.shape)

"""<font size="6" color="darkgreen"><b><u>Model Building</b></u></font>

<font size="6" color="darkred"><b><u>Why Logistic Regression Was Chosen?</b></u></font>
<b><p>

- Selected for its simplicity, interpretability, and efficiency.

- Provides clear insights into feature influence and outputs class probabilities.

- Fast and easy to implement, serving as a baseline for comparison with complex models like Random Forest or XGBoost.

- Effective for multi-class classification, though it assumes linear relationships.
"""

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score

# Train a Logistic Regression model
log_reg = LogisticRegression(max_iter=1000,random_state=42)
log_reg.fit(X_train, y_train)

# Make predictions
y_pred_lr = log_reg.predict(X_test)

# Evaluate
print("Accuracy:", accuracy_score(y_test, y_pred_lr))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred_lr))
print("Classification Report:\n", classification_report(y_test, y_pred_lr, digits=4))

"""<font size="6" color="blue"><b><u>Logistic Regression Model Performance Summary</b></u></font>
<b>

Your Logistic Regression classifier achieved an accuracy of 70.66%, demonstrating a moderate overall performance across the 13 target classes.

<font size="6" color="darkred"><b><u>Evaluation Metrics</b></u></font>

- Accuracy:0.7066 (≈ 70.66%)
The model correctly classified about 71% of the test data.
This indicates moderate performance, reasonable for a 13-class classification task.

- Confusion Matrix:The matrix indicates that while the model captures general class patterns, certain classes show notable misclassifications, particularly among similar or overlapping categories (e.g., classes 1, 7, and 10).
- Classification Report: Displays precision, recall, and F1-score for each class, highlighting areas of both strong and weak performance.

<font size="6" color="blue"><b><u>Average Metrics</b></u></font>

- Macro Average: Precision: 0.7050, Recall: 0.7050, F1-Score: 0.7055

- Weighted Average: Precision: 0.7051, Recall: 0.7066, F1-Score: 0.7056

- These averages suggest consistent and balanced performance across classes, with minimal bias toward any particular category.

<font size="6" color="darkred"><b><u>Insights</b></u></font>

- High-performing classes: 4, 8, 11, and 12 — strong precision and recall, with F1-scores above 0.80.

- Lower-performing classes: 1, 7, and 10 — F1-scores near 0.50 indicate difficulty distinguishing these classes from others.

- The model performs best on clearly separable classes, while overlapping feature distributions may have reduced its accuracy for certain labels.

<font size="6" color="blue"><b><u>Conclusion</b></u></font>

- Logistic Regression provided a solid baseline model with interpretable results and balanced performance across multiple classes. While its 70.66% accuracy shows effective learning of linear relationships, further improvements could be achieved using more complex non-linear models (e.g., Random Forest, XGBoost) or enhanced feature engineering techniques.

<font size="6" color="red"><b><u>Model Building (using multiple models)</b></u></font>
"""

# Import necessary libraries
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.svm import SVC
from sklearn.naive_bayes import GaussianNB
from xgboost import XGBClassifier

# Initialize the classifiers
classifiers = {
    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42),
    'K-Nearest Neighbors': KNeighborsClassifier(),
    'Decision Tree': DecisionTreeClassifier(random_state=42),
    'Random Forest': RandomForestClassifier(random_state=42),
    'Gradient Boosting': GradientBoostingClassifier(random_state=42),
    'Support Vector Machine': SVC(random_state=42),
    'Naive Bayes': GaussianNB(),
    'XGBoost': XGBClassifier(eval_metric='mlogloss', use_label_encoder=False, random_state=42)
}

import warnings

warnings.filterwarnings("ignore")

# Train, evaluate and store results
from sklearn.metrics import accuracy_score, f1_score

# Initialize an empty dictionary to store the results
results = {}

# Train and evaluate each classifier
for name, clf in classifiers.items():
    # Train the model
    clf.fit(X_train_scaled, y_train)
    # Make predictions
    y_pred = clf.predict(X_test_scaled)
    # Calculate metrics
    accuracy = accuracy_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred, average='macro')
    # Store the results
    results[name] = {'Accuracy': accuracy, 'F1 score': f1}

# Convert the results dictionary to a DataFrame
results_df_copy = pd.DataFrame(results).T.sort_values(by='F1 score', ascending=False)

# Print the DataFrame
print("🔹 Model Performance Comparison:\n")
print(results_df_copy)

# Select best model based on F1 score
best_model_name = results_df_copy['F1 score'].idxmax()
print(f"\nBest model for multiclass classification (F1-score prioritized): {best_model_name}")

"""<font size="5" color="magenta"><b><u>Best model for multiclass classification (F1‑score prioritized)</b></u></font>

<b>

<font size="5" color="darkgreen"><b><u>Random Forest</b></u></font>

— It achieves the highest F1 score (0.902313) and the highest accuracy (0.903143) among all models tested.

<font size="5" color="darkred"><b><u>Model Performance Summary</b></u></font>
<b>

We evaluated eight classifiers using accuracy and macro‑F1 score. Random Forest emerged as the top performer, achieving the highest accuracy (0.903143) and highest macro‑F1 score (0.902313) among all models. Since we prioritize F1 score, Random Forest is the best choice overall, balancing precision and recall well across classes. Its strong performance makes it the preferred model for multiclass classification in this task.

<font size="5" color="darkgreen"><b><u>Train the selected model (Random Forest)</b></u></font>
"""

# Train the selected model (Random Forest)
from sklearn.ensemble import RandomForestClassifier
clf = RandomForestClassifier(n_estimators=100, random_state=42)
clf.fit(X_train, y_train)
y_pred = clf.predict(X_test)

# Confusion matrix plot
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix

# After you get predictions:
cm = confusion_matrix(y_test, y_pred)

# labels in correct order
labels = [
    "Steroid-Induced Diabetes",
    "Neonatal Diabetes Mellitus (NDM)",
    "Prediabetic",
    "Type 1 Diabetes",
    "Wolfram Syndrome",
    "LADA",
    "Type 2 Diabetes",
    "Wolcott-Rallison Syndrome",
    "Secondary Diabetes",
    "Type 3c Diabetes (Pancreatogenic Diabetes)",
    "Gestational Diabetes",
    "Cystic Fibrosis‑Related Diabetes (CFRD)",
    "MODY"
]

plt.figure(figsize=(12, 10))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=labels, yticklabels=labels)
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix for Diabetes Type Classification')
plt.xticks(rotation=45, ha='right')
plt.yticks(rotation=0)
plt.tight_layout()
plt.show()

# Model Evaluation: Precision, Recall & Classification Report
from sklearn.metrics import precision_score, recall_score, classification_report
print(f"Precision (macro) = {precision_score(y_test, y_pred, average='macro'):.4f}")
print(f"Recall (macro)    = {recall_score(y_test, y_pred, average='macro'):.4f}")
print("\nClassification Report:\n")
print(classification_report(y_test, y_pred, digits=4))

"""<font size="6" color="darkred"><b><u>Model Performance Summary</b></u></font>
<b>


<font size="6" color="blue"><b><u>Accuracy:</b></u></font>

90.31%, showing strong overall performance.

<font size="6" color="darkred"><b><u>Evaluation Metrics</b></u></font>

- Confusion matrix and classification report indicate high precision, recall, and F1-scores across classes.

<font size="6" color="blue"><b><u>Average Metrics</b></u></font>

- Macro: Precision 0.9077, Recall 0.9035, F1-Score 0.9023

- Weighted: Precision 0.9079, Recall 0.9031, F1-Score 0.9022

- Indicates balanced performance across all classes.

<font size="6" color="darkred"><b><u>Conclusion</b></u></font>

- Random Forest delivers robust, reliable predictions for multiclass diabetes classification, effectively capturing linear and non-linear patterns. Minor improvements possible with additional feature engineering or hyperparameter tuning.

<font size="6" color="darkred"><b><u>Top 3 Models compare</b></u></font>
"""

from sklearn.metrics import accuracy_score, f1_score

# Define top 3 models
top_models = {
    'Random Forest': RandomForestClassifier(random_state=42),
    'Gradient Boosting': GradientBoostingClassifier(random_state=42),
    'XGBoost': XGBClassifier(eval_metric='mlogloss', use_label_encoder=False, random_state=42)
}

# Train, predict, and evaluate
results = []

for name, model in top_models.items():
    model.fit(X_train_scaled, y_train)
    y_pred = model.predict(X_test_scaled)

    accuracy = accuracy_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred, average='macro')

    results.append({
        'Model': name,
        'Accuracy': round(accuracy,4),
        'Macro F1-score': round(f1,4)
    })

# Create DataFrame for comparison
results_df = pd.DataFrame(results).sort_values(by='Accuracy', ascending=False)
print("🔹 Top Model Comparison:\n")
print(results_df)
# Line Plot (connected points)
plt.figure(figsize=(8,5))
plt.plot(results_df['Model'], results_df['Accuracy'], marker='o', label='Accuracy')
plt.plot(results_df['Model'], results_df['Macro F1-score'], marker='s', label='Macro F1-score')
plt.ylabel('Score')
plt.ylim(0,1)
plt.title('Top Model Comparison: Accuracy vs Macro F1-score')
plt.legend()
plt.grid(True, linestyle='--', alpha=0.5)
plt.show()

"""<font size="6" color="darkblue"><b><u>Interpretation</b></u></font>

<font size="6" color="darkred"><b><u>"Top Model Comparison – Accuracy vs Macro F1-score"</b></u></font>

<b>

- Models Compared: Random Forest, Gradient Boosting, and XGBoost.

<font size="6" color="darkblue"><b><u>Observation:</b></u></font>

- All three models achieved very similar performance, with both accuracy and macro F1-score around 0.90.

- The lines for both metrics are nearly flat, indicating minimal variation between models.

<font size="6" color="darkred"><b><u>Inference:</b></u></font>

- Random Forest slightly leads in both accuracy and F1-score, making it the best overall performer.

- Gradient Boosting and XGBoost follow closely behind, showing comparable robustness.

<font size="6" color="darkblue"><b><u>Conclusion:</b></u></font>

- All three ensemble models perform exceptionally well for multiclass classification.

- Random Forest is marginally superior and is therefore the recommended model for deployment.

<font size="6" color="BLACK"><b><u>STAGE-4</b></u></font>

<font size="6" color="red"><b><u>Model Evaluation and Comparison</b></u></font>

<font size="6" color="blue"><b><u>RandomizedSearchCV hyperparameter tuning</b></u></font>

<font size="6" color="ff0080"><b><u>RandomForestClassifier</b></u></font>
"""

from sklearn.model_selection import RandomizedSearchCV
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix, make_scorer

# Define Random Forest and Hyperparameter Space
rf = RandomForestClassifier(random_state=42)

param_dist = {
    'n_estimators': [50, 100, 150],
    'max_depth': [None, 10, 20],
    'min_samples_split': [2, 5],
    'min_samples_leaf': [1, 2],
    'max_features': ['sqrt', 'log2'],
    'bootstrap': [True, False]
}

# RandomizedSearchCV for Hyperparameter Tuning
random_search = RandomizedSearchCV(
    estimator=rf,
    param_distributions=param_dist,
    n_iter=10,  # Number of random combinations
    scoring=make_scorer(f1_score, average='macro'),
    cv=3,  # 3-fold CV
    n_jobs=-1,
    verbose=2,
    random_state=42
)

# Fit the search
random_search.fit(X_train, y_train)

# Best model
best_rf = random_search.best_estimator_
print("Best Hyperparameters:", random_search.best_params_)
print("Best Cross-Validated Macro F1-score:", random_search.best_score_)

from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix, make_scorer
#  Evaluate on Test Set
y_pred = best_rf.predict(X_test)

accuracy = accuracy_score(y_test, y_pred)
macro_f1 = f1_score(y_test, y_pred, average='macro')
weighted_f1 = f1_score(y_test, y_pred, average='weighted')

print(f"\nRandom Forest Hypertuned Performance on Test Set:")
print(f"Accuracy         : {accuracy:.4f}")
print(f"Macro F1-score   : {macro_f1:.4f}")
print(f"Weighted F1-score: {weighted_f1:.4f}\n")

print("Classification Report:\n")
print(classification_report(y_test, y_pred, digits=4))

# Confusion Matrix Plot

cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(10,8))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("Confusion Matrix - Tuned Random Forest")
plt.show()

from sklearn.preprocessing import label_binarize
from sklearn.multiclass import OneVsRestClassifier
from sklearn.metrics import roc_curve, auc
import matplotlib.pyplot as plt
import numpy as np

# Binarize the labels
classes = np.unique(y_test)
y_test_bin = label_binarize(y_test, classes=classes)
n_classes = y_test_bin.shape[1]

# Wrap best classifier in OneVsRest
ovr = OneVsRestClassifier(best_rf)  # best_rf is your tuned Random Forest
ovr.fit(X_train_scaled, y_train)
y_score = ovr.predict_proba(X_test_scaled)

# Plot ROC curves
plt.figure(figsize=(10,8))
for i in range(n_classes):
    fpr, tpr, _ = roc_curve(y_test_bin[:, i], y_score[:, i])
    roc_auc = auc(fpr, tpr)
    plt.plot(fpr, tpr, label=f'Class {classes[i]} (AUC = {roc_auc:.2f})')

plt.plot([0, 1], [0, 1], 'k--', lw=2)
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curves - Best Classifier (Random Forest)')
plt.legend(loc='lower right')
plt.show()

"""<font size="6" color="darkred"><b><u>Random Forest Model Performance Summary (Tuned with RandomizedSearchCV)</b></u></font>
<b>
- Near-Perfect ROC-AUC: 0.99–1.00 across all 13 classes, indicating excellent class separation and discrimination.

- High Accuracy & F1-Score: Minimal misclassification; outperforms other classifiers.

- Low False Positives / High True Positives: TPR ≈ 1.0, FPR ≈ 0.0, correctly identifying almost all samples.

- Balanced Across Classes: Consistent performance with no class underperforming.

- Overfitting Check: Near-perfect AUC may indicate minor overfitting; validate with cross-validation or unseen test data.
<font size="6" color="blue"><b><u>Conclusion</b></u></font>
<b>
 - Random Forest is the most reliable model for multiclass diabetes classification.

<font size="6" color="darkred"><b><u>Diabetes Type Prediction Using Random Forest (Tuned with RandomizedSearchCV)</b></u></font>
"""

# Sample input with top 30 features
sample_input = {
    'Risk_Score': 92.1,
    'Age': 45,
    'Blood Pressure': 130,
    'Blood Glucose Levels': 210,
    'Weight Gain During Pregnancy': 8.5,
    'Cholesterol Levels': 220,
    'Waist Circumference': 95,
    'Digestive Enzyme Levels': 60,
    'Age_Group': 3,
    'BMI': 29.3,
    'Pulmonary Function': 88,
    'Insulin Levels': 14.2,
    'Birth Weight': 3.5,
    'Neurological Assessments': 75,
    'Pancreatic Health': 65,
    'BMI_Category': 2,
    'High_Risk_Pregnancy': 0,
    'Socioeconomic Factors': 1,
    'Pregnancy History': 1,
    'Urine Test_Protein Present': 1,
    'Genetic Markers_Positive': 0,
    'Urine Test_Ketones Present': 1,
    'Physical Activity': 2,
    'Environmental Factors_Present': 1,
    'Smoking Status': 0,
    'Ethnicity_Low Risk': 1,
    'Dietary Habits': 3,
    'Steroid Use History_Yes': 1,
    'Urine Test_Normal': 0,
    'History of PCOS': 1
}
# Top 30 selected features
selected_features = [
    'Risk_Score', 'Age', 'Blood Pressure', 'Blood Glucose Levels',
    'Weight Gain During Pregnancy', 'Cholesterol Levels', 'Waist Circumference',
    'Digestive Enzyme Levels', 'Age_Group', 'BMI', 'Pulmonary Function',
    'Insulin Levels', 'Birth Weight', 'Neurological Assessments',
    'Pancreatic Health', 'BMI_Category', 'High_Risk_Pregnancy',
    'Socioeconomic Factors', 'Pregnancy History', 'Urine Test_Protein Present',
    'Genetic Markers_Positive', 'Urine Test_Ketones Present',
    'Physical Activity', 'Environmental Factors_Present', 'Smoking Status',
    'Ethnicity_Low Risk', 'Dietary Habits', 'Steroid Use History_Yes',
    'Urine Test_Normal', 'History of PCOS'
]
# Class mapping
class_mapping = {
    0: "Steroid-Induced Diabetes",
    1: "Neonatal Diabetes Mellitus (NDM)",
    2: "Prediabetic",
    3: "Type 1 Diabetes",
    4: "Wolfram Syndrome",
    5: "LADA",
    6: "Type 2 Diabetes",
    7: "Wolcott-Rallison Syndrome",
    8: "Secondary Diabetes",
    9: "Type 3c Diabetes (Pancreatogenic Diabetes)",
    10: "Gestational Diabetes",
    11: "Cystic Fibrosis‑Related Diabetes (CFRD)",
    12: "MODY"
}

df_copy = pd.DataFrame([sample_input])
df_copy = df_copy[selected_features]

# Align features with scaler
for col in scaler.feature_names_in_:
    if col not in df_copy.columns:
        df_copy[col] = 0
df_copy = df_copy[scaler.feature_names_in_]

# Scale input
input_scaled = scaler.transform(df_copy)

# Predict
y_pred_proba = best_rf.predict_proba(input_scaled)[0]

# Map probabilities to class names
class_probs = {class_mapping[i]: y_pred_proba[i] for i in range(len(y_pred_proba))}

# Top 3 predictions
top_3 = sorted(class_probs.items(), key=lambda x: x[1], reverse=True)[:3]

# Display
print(" Best Model: Random Forest")
print(f"Top Predicted Diabetes Type: {top_3[0][0]} ({top_3[0][1]*100:.2f}%)\n")

print("Top 3 Predicted Diabetes Types:")
for cls, prob in top_3:
    print(f"{cls:45s}: {prob*100:.2f}%")

print("\nPredicted Class Probabilities for All Diabetes Types\n")
for cls, prob in class_probs.items():
    print(f"{cls:45s}: {prob*100:.2f}%")

# Plot All Class Probabilities
# Sort by probability
sorted_classes = sorted(class_probs.items(), key=lambda x: x[1], reverse=True)
classes, probs = zip(*sorted_classes)
probs_percent = [p*100 for p in probs]

# Highlight top 3
colors = ['orange' if i < 3 else 'skyblue' for i in range(len(classes))]

plt.figure(figsize=(14,6))
bars = plt.barh(classes, probs_percent, color=colors)
plt.xlabel("Probability (%)")
plt.title("Predicted Probabilities for All Diabetes Types (Top 3 Highlighted)")
plt.xlim(0, 100)

# Add value labels
for bar, prob in zip(bars, probs_percent):
    plt.text(bar.get_width() + 1, bar.get_y() + bar.get_height()/2,
             f"{prob:.2f}%", va='center')

plt.gca().invert_yaxis()  # highest probability on top
plt.tight_layout()
plt.show()

"""<font size="6" color="darkgreen"><b><u>Input & Output Prediction Results: Random Forest Classifier (RandomizedSearchCV)</b></u></font>
<b>
- Model: Random Forest optimized with RandomizedSearchCV to classify 13 diabetes subtypes using 30 clinical, biochemical, and demographic features.

- Performance: High accuracy and balanced macro F1-score, demonstrating strong generalization.

- Predictions: Most probable subtype — Wolfram Syndrome (67.89%), followed by CFRD (11.94%) and Steroid-Induced Diabetes (8.67%).

- Utility: Multi-class probability output supports differential diagnosis and data-driven clinical decisions.

- Conclusion: Random Forest is the most reliable model for predicting diabetes subtypes using diverse clinical factors.

<font size="6" color="darkred"><b><u>Hyperparameter Tuning RandomizedSearchCV Combine three classifers model</b></u></font>
<b>
- RandomizedSearchCV for Random Forest, Logistic Regression, and Naive Bayes and then evaluates all three models on the test set with Accuracy, Macro F1, Weighted F1, and ROC/AUC.
"""

# Multiclass Model Comparison with RandomizedSearchCV + ROC/AUU
# Imports
from sklearn.model_selection import RandomizedSearchCV
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import GaussianNB
from sklearn.preprocessing import StandardScaler, label_binarize
from sklearn.multiclass import OneVsRestClassifier
from sklearn.metrics import accuracy_score, f1_score, roc_curve, auc, classification_report
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np

# Models and Hyperparameters
models = {
    "Random Forest": (
        RandomForestClassifier(random_state=42),
        {
            'n_estimators': [50, 100, 150],
            'max_depth': [None, 10, 20],
            'min_samples_split': [2, 5],
            'min_samples_leaf': [1, 2],
            'max_features': ['sqrt', 'log2']
        }
    ),
  "Logistic Regression": (
        LogisticRegression(max_iter=2000, multi_class='multinomial', solver='lbfgs', random_state=42),
        {'C': [0.01, 0.1, 1, 10]}
    ),
      "Naive Bayes": (
        GaussianNB(),
        {}  # No hyperparameters
    )
}
# Train and Evaluate
results = []
best_models_dict = {}

for name, (model, params) in models.items():
    print(f"\nRunning RandomizedSearchCV for {name}...")

    if params:
        search = RandomizedSearchCV(
            estimator=model,
            param_distributions=params,
            n_iter=5,
            scoring='f1_macro',
            cv=3,
            n_jobs=-1,
            verbose=1,
            random_state=42
        )
        search.fit(X_train_scaled, y_train)
        best_model = search.best_estimator_
        print(f" Best Params for {name}: {search.best_params_}")
    else:
        best_model = model
        best_model.fit(X_train_scaled, y_train)

    # Save best model
    best_models_dict[name] = best_model

    # Predictions & Metrics
    y_pred = best_model.predict(X_test_scaled)
    acc = accuracy_score(y_test, y_pred)
    f1_macro = f1_score(y_test, y_pred, average='macro')
    f1_weighted = f1_score(y_test, y_pred, average='weighted')

    results.append((name, acc, f1_macro, f1_weighted))

    print(f"\n📊 {name} Performance:")
    print(f"Accuracy         : {acc:.4f}")
    print(f"Macro F1-score   : {f1_macro:.4f}")
    print(f"Weighted F1-score: {f1_weighted:.4f}")
    print(classification_report(y_test, y_pred, digits=4))

# Compare Models
results_df = pd.DataFrame(results, columns=['Model', 'Accuracy', 'Macro F1', 'Weighted F1'])
results_df.sort_values(by='Macro F1', ascending=False, inplace=True)
print("\nModel Comparison:")
print(results_df)

# ROC / AUC for Best Model
best_model_name = results_df.iloc[0, 0]
best_model = best_models_dict[best_model_name]

if hasattr(best_model, "predict_proba"):
    ovr = OneVsRestClassifier(best_model)
    ovr.fit(X_train_scaled, y_train)
    y_score = ovr.predict_proba(X_test_scaled)

    classes = np.unique(y_test)
    y_test_bin = label_binarize(y_test, classes=classes)
    n_classes = y_test_bin.shape[1]

    plt.figure(figsize=(10, 8))
    for i in range(n_classes):
        fpr, tpr, _ = roc_curve(y_test_bin[:, i], y_score[:, i])
        roc_auc = auc(fpr, tpr)
        plt.plot(fpr, tpr, label=f'Class {classes[i]} (AUC = {roc_auc:.2f})')

    plt.plot([0, 1], [0, 1], 'k--', lw=2)
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title(f'ROC Curves - Best Classifier ({best_model_name})')
    plt.legend(loc='lower right')
    plt.show()
else:
    print(f"ROC Curve not available for {best_model_name} (no probability output).")

"""<font size="6" color="darkgreen"><b><u>“Final Sample Input & Output Prediction — Hyperparameter Tuning with RandomizedSearchCV and Combined Classifier Models”</b></u></font>
<b>
"""

# Imports
import pandas as pd
import numpy as np

# Sample Input
sample_input = {
    'Risk_Score': 92.1,
    'Age': 45,
    'Blood Pressure': 130,
    'Blood Glucose Levels': 210,
    'Weight Gain During Pregnancy': 8.5,
    'Cholesterol Levels': 220,
    'Waist Circumference': 95,
    'Digestive Enzyme Levels': 60,
    'Age_Group': 3,
    'BMI': 29.3,
    'Pulmonary Function': 88,
    'Insulin Levels': 14.2,
    'Birth Weight': 3.5,
    'Neurological Assessments': 75,
    'Pancreatic Health': 65,
    'BMI_Category': 2,
    'High_Risk_Pregnancy': 0,
    'Socioeconomic Factors': 1,
    'Pregnancy History': 1,
    'Urine Test_Protein Present': 1,
    'Genetic Markers_Positive': 0,
    'Urine Test_Ketones Present': 1,
    'Physical Activity': 2,
    'Environmental Factors_Present': 1,
    'Smoking Status': 0,
    'Ethnicity_Low Risk': 1,
    'Dietary Habits': 3,
    'Steroid Use History_Yes': 1,
    'Urine Test_Normal': 0,
    'History of PCOS': 1
}

# Top Features
selected_features = [
    'Risk_Score', 'Age', 'Blood Pressure', 'Blood Glucose Levels',
    'Weight Gain During Pregnancy', 'Cholesterol Levels', 'Waist Circumference',
    'Digestive Enzyme Levels', 'Age_Group', 'BMI', 'Pulmonary Function',
    'Insulin Levels', 'Birth Weight', 'Neurological Assessments',
    'Pancreatic Health', 'BMI_Category', 'High_Risk_Pregnancy',
    'Socioeconomic Factors', 'Pregnancy History', 'Urine Test_Protein Present',
    'Genetic Markers_Positive', 'Urine Test_Ketones Present',
    'Physical Activity', 'Environmental Factors_Present', 'Smoking Status',
    'Ethnicity_Low Risk', 'Dietary Habits', 'Steroid Use History_Yes',
    'Urine Test_Normal', 'History of PCOS'
]

# Class Mapping
class_mapping = {
    0: "Steroid-Induced Diabetes",
    1: "Neonatal Diabetes Mellitus (NDM)",
    2: "Prediabetic",
    3: "Type 1 Diabetes",
    4: "Wolfram Syndrome",
    5: "LADA",
    6: "Type 2 Diabetes",
    7: "Wolcott-Rallison Syndrome",
    8: "Secondary Diabetes",
    9: "Type 3c Diabetes (Pancreatogenic Diabetes)",
    10: "Gestational Diabetes",
    11: "Cystic Fibrosis‑Related Diabetes (CFRD)",
    12: "MODY"
}

# Prepare DataFrame
df_copy = pd.DataFrame([sample_input])
df_copy = df_copy[selected_features]

# Align with scaler (add missing columns)
for col in scaler.feature_names_in_:
    if col not in df_copy.columns:
        df_copy[col] = 0
df_copy = df_copy[scaler.feature_names_in_]

# Scale input
input_scaled = scaler.transform(df_copy)

#  Predict & Display
for model_name, model in best_models_dict.items():
    print(f"\n--- Predictions by {model_name} ---")

    if hasattr(model, "predict_proba"):
        probs = model.predict_proba(input_scaled)[0]
        class_probs = {class_mapping[i]: probs[i] for i in range(len(probs))}

        # Display all class probabilities
        print("\nClass Probabilities:")
        for cls, prob in class_probs.items():
            print(f"{cls:45s}: {prob*100:.2f}%")

        # Display top 3 predictions
        top_3 = sorted(class_probs.items(), key=lambda x: x[1], reverse=True)[:3]
        print("\nTop 3 Predictions:")
        for cls, prob in top_3:
            print(f"{cls:45s}: {prob*100:.2f}%")
    else:
        pred_class = model.predict(input_scaled)[0]
        print(f"Predicted Class: {class_mapping[pred_class]} (no probability output)")

# Top Model Prediction
best_model_name = results_df.iloc[0, 0]
best_model = best_models_dict[best_model_name]

y_pred_proba = best_model.predict_proba(input_scaled)[0]
class_probs = {class_mapping[i]: y_pred_proba[i] for i in range(len(y_pred_proba))}
top_3 = sorted(class_probs.items(), key=lambda x: x[1], reverse=True)[:3]

print(f"\nFinal Top Predictions by Best Model ({best_model_name})")
print(f"Top Predicted Diabetes Type: {top_3[0][0]} ({top_3[0][1]*100:.2f}%)")
print("Top 3 Predictions:")
for cls, prob in top_3:
    print(f"{cls:45s}: {prob*100:.2f}%")

"""<font size="6" color="darkgreen"><b><u>"Multimodel Diabetes Type Prediction with Probability Visualization"</b></u></font>"""

import matplotlib.pyplot as plt

# Bar chart function
def plot_class_probs(model_name, class_probs):
    """
    Draws a bar chart for predicted class probabilities.
    Top 3 predictions are highlighted in orange.
    """
    sorted_classes = sorted(class_probs.items(), key=lambda x: x[1], reverse=True)
    classes, probs = zip(*sorted_classes)
    probs_percent = [p * 100 for p in probs]
    colors = ['orange' if i < 3 else 'skyblue' for i in range(len(classes))]

    plt.figure(figsize=(14, 6))
    bars = plt.barh(classes, probs_percent, color=colors)
    plt.xlabel("Probability (%)", fontsize=12)
    plt.ylabel("Diabetes Type", fontsize=12)
    plt.title(f"Predicted Probabilities by {model_name} (Top 3 Highlighted)", fontsize=14)
    plt.xlim(0, 100)

    for bar, prob in zip(bars, probs_percent):
        plt.text(bar.get_width() + 1, bar.get_y() + bar.get_height()/2,
                 f"{prob:.2f}%", va='center', fontsize=10)
    plt.gca().invert_yaxis()
    plt.tight_layout()
    plt.show()

# Random Forest
probs_rf = best_models_dict["Random Forest"].predict_proba(input_scaled)[0]
class_probs_rf = {class_mapping[i]: probs_rf[i] for i in range(len(probs_rf))}

# Logistic Regression
probs_logreg = best_models_dict["Logistic Regression"].predict_proba(input_scaled)[0]
class_probs_logreg = {class_mapping[i]: probs_logreg[i] for i in range(len(probs_logreg))}

# Naive Bayes
probs_nb = best_models_dict["Naive Bayes"].predict_proba(input_scaled)[0]
class_probs_nb = {class_mapping[i]: probs_nb[i] for i in range(len(probs_nb))}


# --- Plot each model’s probabilities ---
plot_class_probs("Random Forest", class_probs_rf)
plot_class_probs("Logistic Regression", class_probs_logreg)
plot_class_probs("Naive Bayes", class_probs_nb)

"""<font size="6" color="darkgreen"><b><u>Final Summary – Multimodel Diabetes Type Prediction</b></u></font>
<b>

<font size="6" color="darkred"><b><u>Objective</b></u></font>

- Predict the most probable diabetes subtype for a patient sample using three machine learning classifiers—Random Forest, Logistic Regression, and Naive Bayes—optimized with RandomizedSearchCV.

<font size="6" color="darkgreen"><b><u>Methodology</b></u></font>

<font size="5" color="darkred"><b><u>Data Preparation:</b></u></font>

- Selected top 30 clinical, genetic, and lifestyle features.

- Scaled features using StandardScaler.

- Encoded 13 diabetes subtype classes.

<font size="5" color="darkred"><b><u>Model Training:</b></u></font>

- Tuned each model with RandomizedSearchCV (3-fold CV) using f1_macro.

- Saved best model configurations for predictions.

<font size="5" color="darkred"><b><u>Evaluation Metrics:</b></u></font>

- Compared Accuracy, Macro F1, and Weighted F1.

- Plotted ROC–AUC curves for the best model.


<font size="5" color="darkred"><b><u>Model Performance Comparison</b></u></font>

| Model               |  Accuracy  |  Macro F1  | Weighted F1 |
| :------------------ | :--------: | :--------: | :---------: |
| **Random Forest**   | **0.9042** | **0.9034** |  **0.9033** |
| Logistic Regression |   0.7663   |   0.7655   |    0.7657   |
| Naive Bayes         |   0.7411   |   0.7376   |    0.7370   |

<font size="6" color="darkgreen"><b><u>Best Model: Random Forest</b></u></font>

<font size="5" color="darkred"><b><u>Sample Input Predictions</b></u></font>

<font size="5" color="darkgreen"><b><u>Random Forest (Best Model)</b></u></font>

- Top Prediction: Wolcott-Rallison Syndrome — 35.95%

- Second: Prediabetic — 31.68%

- Third: Type 3c Diabetes (Pancreatogenic) — 10.10%

<font size="5" color="darkgreen"><b><u>Logistic Regression</b></u></font>

- Top Prediction: Gestational Diabetes — 98.26%

<font size="5" color="darkgreen"><b><u>Naive Bayes</b></u></font>

- Top Prediction: Type 3c Diabetes (Pancreatogenic) — 100.00%

<font size="6" color="darkred"><b><u>Final Decision</b></u></font>

- Chosen Model: Random Forest

- Final Predicted Diabetes Type: Wolcott-Rallison Syndrome (35.95%)

<font size="6" color="darkgreen"><b><u>Insights</b></u></font>

- Random Forest gave the most balanced probabilities across classes.

- Logistic Regression showed strong linear bias, while Naive Bayes was overconfident in one class.

- RandomizedSearchCV optimized hyperparameters for better generalization.

- Probability bar charts effectively visualize the top 3 predicted classes for each model.

<font size="6" color="darkred"><b><u>Final Conclusion:</b></u></font>

<p><font size="4">

- Among the three models—Random Forest, Logistic Regression, and Naive Bayes—Random Forest provided the most accurate, balanced, and interpretable multiclass diabetes predictions. It identified Wolcott-Rallison Syndrome as the most probable subtype, outperforming the other models in reliability and overall performance across clinical, genetic, and lifestyle features.

<font size="6" color="darkgreen"><b><u>Future Enhancements</b></u></font>
<B>

1.Hyperparameter Optimization: Use finer GridSearch or Bayesian optimization.

2.Feature Engineering: Add derived features, feature selection, or PCA.

3.Class Imbalance Handling: Use SMOTE or class weighting.

4.Ensemble Learning: Explore stacking or boosting (XGBoost, LightGBM).

5.Data Expansion: Incorporate additional genetic/environmental/lifestyle factors.

6.Deployment & Monitoring: Real-time prediction pipeline with continuous monitoring and retraining.

<font size="6" color="darkred"><b><u>Model Optimization</b></u></font>
<B>

1.Address Class Imbalance

- Apply SMOTE, class weighting, or targeted oversampling/undersampling to improve predictions for underrepresented classes.

2.Ensemble Techniques

- Combine your trained models (Random Forest, Logistic Regression, Naive Bayes) using stacking to leverage complementary strengths.

- Explore boosting models like XGBoost, LightGBM, or CatBoost for higher predictive performance.

3.Cross-Validation Enhancements

- Use stratified k-fold cross-validation to ensure consistent performance across all classes.

- Monitor metrics per fold to detect potential overfitting.

4.Model Deployment & Monitoring

- Deploy the model in a real-time or batch prediction pipeline.

- Continuously monitor predictions and retrain periodically with new incoming data.

5.Additional Data Integration

- If possible, incorporate more genetic, environmental, or lifestyle samples/features to improve generalization and robustness.
"""