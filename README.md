# Main_project-ML-Comprehensive-Diabetes-Dataset-with-Genetic-Environmental-and-Lifestyle-Factors
**PROJECT TITLE**

Comprehensive Diabetes Dataset with Genetic, Environmental, and Lifestyle Factors

**PROBLEM STATEMENT**

Diabetes mellitus includes multiple subtypes, each with distinct causes and progression patterns. Understanding how genetic, environmental, and lifestyle factors interact is essential for personalized healthcare. This project analyses a comprehensive dataset covering Steroid-Induced Diabetes, Neonatal Diabetes Mellitus (NDM), Prediabetes, Type 1 Diabetes, and Wolfram Syndrome to identify unique and shared risk factors. The challenge is to determine which factor combinations contribute to each subtype, enabling better diagnosis, targeted interventions, and effective disease management.

**PROJECT OVERVIEW**

This project uses a comprehensive dataset encompassing multiple diabetes subtypes, including Steroid‚ÄëInduced Diabetes, Neonatal Diabetes Mellitus (NDM), Prediabetes, Type 1 Diabetes, and Wolfram Syndrome. The dataset includes medical, genetic, environmental, and lifestyle attributes to provide a holistic view of each patient‚Äôs profile. The aim is to help researchers and healthcare professionals understand how these factors interact and contribute to the development and progression of different diabetes subtypes, enabling insights for personalized treatment, risk assessment, and improved disease management.

**Goals**

**1.Risk Prediction:**

Predict likelihood of developing specific diabetes subtypes using genetic, environmental, lifestyle, and medical data

**2.Feature Analysis & Interpretation:**

Identify key factors and their interactions influencing each subtype.

**3.Subtype Classification:**

Build a model to distinguish among the different diabetes types using available data (e.g. classify a new patient into Type 1 vs NDM vs Steroid‚ÄëInduced, etc.).

**4.Public Health Insights:**

Inform preventive strategies to reduce risk, especially in genetically susceptible populations.


**Domain:**

Healthcare Analytics / Machine Learning for Disease Prediction

**Objective:**

1.Predictive Modelling: Develop a model to identify individuals at high risk of developing diabetes, supporting early intervention and personalized healthcare.

2.Classification: Classify individuals as diabetic or non-diabetic based on genetic, environmental, and lifestyle factors.

**Type of problem:**

****Classification (predict diabetes type / diabetes status)**

**Target feature**
**
**Target feature 1 - Diabetes_Subtype**

**Target Classes / Values**

**Class Value Description**

0: "Steroid-Induced Diabetes",

1: "Neonatal Diabetes Mellitus (NDM)",

2: "Prediabetic",

3: "Type 1 Diabetes",

4: "Wolfram Syndrome",

5: "LADA",

6: "Type 2 Diabetes",

7: "Wolcott-Rallison Syndrome",

8: "Secondary Diabetes",

9: "Type 3c Diabetes (Pancreatogenic Diabetes)",

10: "Gestational Diabetes",

11: "Cystic Fibrosis‚ÄëRelated Diabetes (CFRD)",

12: "MODY"

**Input feature**

feature1,feature 2....feature N All the other columns (except target)

1.Genetic Markers

2.Autoantibodies

3.Family History

4.Environmental Factors

5.Insulin Levels

6.Age

7.BMI (Body Mass Index)

8.Physical Activity

9.Dietary Habits

10.Blood Pressure

11.Cholesterol Levels

12.Waist Circumference

13.Blood Glucose Levels

14.Ethnicity

15.Socioeconomic Factors

16.Smoking Status

17.Alcohol Consumption

18.Glucose Tolerance Test

19.History of PCOS (Polycystic Ovary Syndrome)

20.Previous Gestational Diabetes

21.Pregnancy History

22.Weight Gain During Pregnancy

23.Pancreatic Health

24.Pulmonary Function

25.Cystic Fibrosis Diagnosis

26.Steroid Use History

27.Genetic Testing

28.Neurological Assessments

29.Liver Function Tests

30.Digestive Enzyme Levels

31.Urine Test

32.Birth Weight

33.Early Onset Symptoms

**Outcome:**

**Diabetes Subtype Prediction Report**

**Patient / Sample Input Features**
**
**Feature	Value****

Risk Score	92.1
Age	45
Blood Pressure	130
Blood Glucose Levels	210
Weight Gain During Pregnancy	8.5
Cholesterol Levels	220
Waist Circumference	95
Digestive Enzyme Levels	60
Age Group	3
BMI	29.3
Pulmonary Function	88
Insulin Levels	14.2
Birth Weight	3.5
Neurological Assessments	75
Pancreatic Health	65
BMI Category	2
Genetic Marker 1	1
Family History	Yes
Air Pollution Index	75
Diet Score	6
Physical Activity	Low
Fasting Glucose	120 mg/dL
Insulin Level	10 ¬µIU/mL
‚Ä¶	‚Ä¶
**Sample Output**

**Predicted Diabetes Subtype Probabilities**

**Diabetes Subtype	Probability**
Prediabetes	0.65
Type 1 Diabetes	0.15
Steroid-Induced Diabetes	0.05
Wolfram Syndrome	0.02
NDM (Neonatal Diabetes Mellitus)	0.13
Predicted Subtype: Prediabetes

**Interpretation**
ÔÉº	**Genetic Factors:** Presence of Genetic_Marker_1 significantly increases Prediabetes risk.

ÔÉº**Lifestyle & Clinical Factors:** High BMI and moderate diet score further elevate risk.

ÔÉº	**Model Insight:** Effectively captures complex interactions between genetic, clinical, and lifestyle variables, which may be missed by linear models.

**Sample Final Decision**

Chosen Model

‚Ä¢	**Reason for Selection:** High accuracy, interpretability, and strong performance in multiclass diabetes subtype prediction.

‚Ä¢	**Final Prediction:** Wolcott-Rallison Syndrome (55.95%)

‚Ä¢	Although Prediabetes had the highest single-class probability (0.65), the final prediction incorporates overall model confidence, clinical relevance, and ensemble decision logic to ensure a data-driven and clinically meaningful outcome.

**Steps taken in projects:**

**STAGE-1**
Dateset selection with Initial EDA

**Information about the dataset**


ÔÅ∂	Shape of the dataset:70000,34


ÔÅ∂	Number of columns:34


ÔÅ∂	Number of rows:70000


ÔÅ∂	Number of duplicate rows: 0


ÔÅ∂	Checking the nulls values:0

**What are the algorithms you are going to use?**

ÔÅ∂	For classification tasks like diabetes prediction,algorithm

ÔÅ∂	**Logistic Regression:** A fundamental algorithm for binary classification.

ÔÅ∂	**Decision Tree Classifier:** Decision Tree Classifier: Provides clear decision-making logic.

ÔÅ∂	**Random Forest Classifier:** Random Forest Classifier: An ensemble method that reduces overfitting.

ÔÅ∂	**Gradient Boosting Machines (GBM)**: Gradient Boosting Machines (GBM): Builds models sequentially to correct errors. Support Vector Machine (SVM): Effective in high-dimensional spaces.

ÔÅ∂	**K-Nearest Neighbors:K-Nearest Neighbors:** (Classifies based on proximity to neighbors.KNN)

ÔÅ∂	**Naive Bayes:** Assumes independence among features.

**üìà Model Evaluation Metrics**

ÔÅ∂	**Accuracy:** Proportion of correct predictions.

ÔÅ∂	**Precision:** Proportion of positive predictions that are actually correct.

ÔÅ∂	**Recall (Sensitivity):** Proportion of actual positives correctly identified.

ÔÅ∂	**F1-Score:** Harmonic mean of precision and recall.

ÔÅ∂	**Area Under ROC Curve (AUC-ROC):** Performance measurement for classification problems at various thresholds settings.

**Perform Hyperparameter Tuning**

Utilize techniques like Grid Search or Randomized Search to find the best hyperparameters:
ÔÅ∂	**Grid Search:** Exhaustively tests all combinations in the hyperparameter grid.

ÔÅ∂	**Randomized Search:** Samples a fixed number of hyperparameter combinations from the grid, offering a balance between exploration and computational efficiency.

ÔÅ∂	->This dataset going to use Randomized Search CV

**Evaluate Model Performance**

ÔÅ∂	After tuning, assess the model‚Äôs performance using metrics like Accuracy, Precision, Recall, F1-Score, and AUC-ROC
ÔÅ∂	
**‚ÄúFinal Sample Input & Output Prediction ‚Äî Hyperparameter Tuning with RandomizedSearchCV and Combined Classifier Models‚Äù**


**STAGE-2**

EDA (Visualization) and Pre-processing

**Outliers and Skewness**
**Steps:**
1.	Identify numeric columns
2.	Shape Before Removing Outliers
3.	Skewness Before Outlier Removal
4.	Boxplots Before Removing Outliers
5.	Removing Outliers Using IQR Method
6.	Shape After Removing Outliers
7.	Skewness After Outlier Removal
8.	Boxplots After Removing Outliers
9.	Compare histograms / KDE before vs after display
10.	Applying Transformations (Log/Square Root)
11.	Skewness After Transformation
12.	Boxplots After Transformation

**Visualizations**

1.Univariate

2.Bivariate

3.Multivariate

**STAGE-3**

**Feature Selection and Model Building (using multiple models)**

**Feature Engineering

Feature Creation**

**Separate features and target

-->Feature Scaling

-->Feature Selection

Model Building

-->Model Building (using multiple models)

-->Train the selected  best model**

**STAGE-4**

**Model Evaluation and Comparison**

**-->RandomizedSearchCV hyperparameter tuning

RandomForestClassifier**

@**Diabetes Type Prediction Using Random Forest (Tuned with RandomizedSearchCV)**

@**Hyperparameter Tuning RandomizedSearchCV Combine three classifers model**

@**‚ÄúFinal Sample Input & Output Prediction ‚Äî Hyperparameter Tuning with RandomizedSearchCV and Combined Classifier Models‚Äù**

@**"Multimodel Diabetes Type Prediction with Probability Visualization"**

@**Final Summary ‚Äì Multimodel Diabetes Type Prediction**

@**Future Enhancements**

@**Model Optimization**


